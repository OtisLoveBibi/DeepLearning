{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Data\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "(xTrainSet, yTrainSet), (xTest, yTest) = fashion_mnist.load_data()\n",
    "\n",
    "#Split Data\n",
    "from sklearn.model_selection import train_test_split\n",
    "xTrain, xValid, yTrain, yValid = train_test_split(xTrainSet, yTrainSet, random_state=1)\n",
    "\n",
    "#Preporcessing\n",
    "xTrain = xTrain/255\n",
    "xValid = xValid/255\n",
    "xTest = xTest/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitData(x, y):\n",
    "    indB = (y==4) | (y==5)\n",
    "    yB = (y[indB] == 5). astype(np.float32)\n",
    "    yA = y[~indB]\n",
    "    yA[yA > 5] -= 2\n",
    "    return (x[~indB], yA), (x[indB], yB)\n",
    "(xTrainA, yTrainA), (xTrainB, yTrainB) = splitData(xTrain, yTrain)\n",
    "(xValidA, yValidA), (xValidB, yValidB) = splitData(xValid, yValid)\n",
    "(xTestA, yTestA), (xTestB, yTestB) = splitData(xTest, yTest)\n",
    "\n",
    "xTrainB, yTrainB = xTrainB[:100], yTrainB[:100]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((35968, 28, 28), array([0, 7, 6, 2, 2, 1, 1, 1, 6, 7], dtype=uint8))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xTrainA.shape, yTrainA[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100, 28, 28), array([1., 0., 0., 0., 1., 1., 1., 0., 0., 0.], dtype=float32))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xTrainB.shape, yTrainB[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(1)\n",
    "tf.random.set_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelA = keras.models.Sequential()\n",
    "modelA.add(keras.layers.Flatten(input_shape=[28,28]))\n",
    "for hidden_i in (200, 150,100, 50):\n",
    "    modelA.add(keras.layers.Dense(hidden_i, activation='relu'))\n",
    "modelA.add(keras.layers.Dense(8, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 200)               157000    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 150)               30150     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 100)               15100     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 8)                 408       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 207,708\n",
      "Trainable params: 207,708\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelA.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.SGD`.\n"
     ]
    }
   ],
   "source": [
    "modelA.compile(loss='sparse_categorical_crossentropy', optimizer=keras.optimizers.SGD(learning_rate=1e-3), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "   1/1124 [..............................] - ETA: 2:38 - loss: 2.0620 - accuracy: 0.1562"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-17 11:54:24.374425: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1124/1124 [==============================] - 1s 903us/step - loss: 1.5913 - accuracy: 0.5239 - val_loss: 1.0543 - val_accuracy: 0.7105\n",
      "Epoch 2/20\n",
      "1124/1124 [==============================] - 1s 810us/step - loss: 0.7898 - accuracy: 0.7791 - val_loss: 0.6329 - val_accuracy: 0.7980\n",
      "Epoch 3/20\n",
      "1124/1124 [==============================] - 1s 797us/step - loss: 0.5820 - accuracy: 0.8022 - val_loss: 0.5423 - val_accuracy: 0.8073\n",
      "Epoch 4/20\n",
      "1124/1124 [==============================] - 1s 825us/step - loss: 0.5219 - accuracy: 0.8133 - val_loss: 0.5024 - val_accuracy: 0.8203\n",
      "Epoch 5/20\n",
      "1124/1124 [==============================] - 1s 807us/step - loss: 0.4907 - accuracy: 0.8241 - val_loss: 0.4852 - val_accuracy: 0.8212\n",
      "Epoch 6/20\n",
      "1124/1124 [==============================] - 1s 784us/step - loss: 0.4691 - accuracy: 0.8299 - val_loss: 0.4603 - val_accuracy: 0.8336\n",
      "Epoch 7/20\n",
      "1124/1124 [==============================] - 1s 807us/step - loss: 0.4519 - accuracy: 0.8366 - val_loss: 0.4475 - val_accuracy: 0.8373\n",
      "Epoch 8/20\n",
      "1124/1124 [==============================] - 1s 796us/step - loss: 0.4372 - accuracy: 0.8445 - val_loss: 0.4296 - val_accuracy: 0.8459\n",
      "Epoch 9/20\n",
      "1124/1124 [==============================] - 1s 797us/step - loss: 0.4241 - accuracy: 0.8498 - val_loss: 0.4183 - val_accuracy: 0.8524\n",
      "Epoch 10/20\n",
      "1124/1124 [==============================] - 1s 796us/step - loss: 0.4131 - accuracy: 0.8549 - val_loss: 0.4093 - val_accuracy: 0.8524\n",
      "Epoch 11/20\n",
      "1124/1124 [==============================] - 1s 798us/step - loss: 0.4028 - accuracy: 0.8574 - val_loss: 0.3979 - val_accuracy: 0.8570\n",
      "Epoch 12/20\n",
      "1124/1124 [==============================] - 1s 795us/step - loss: 0.3945 - accuracy: 0.8608 - val_loss: 0.3933 - val_accuracy: 0.8594\n",
      "Epoch 13/20\n",
      "1124/1124 [==============================] - 1s 794us/step - loss: 0.3870 - accuracy: 0.8637 - val_loss: 0.3870 - val_accuracy: 0.8620\n",
      "Epoch 14/20\n",
      "1124/1124 [==============================] - 1s 774us/step - loss: 0.3804 - accuracy: 0.8666 - val_loss: 0.3779 - val_accuracy: 0.8643\n",
      "Epoch 15/20\n",
      "1124/1124 [==============================] - 1s 776us/step - loss: 0.3744 - accuracy: 0.8692 - val_loss: 0.3797 - val_accuracy: 0.8666\n",
      "Epoch 16/20\n",
      "1124/1124 [==============================] - 1s 792us/step - loss: 0.3689 - accuracy: 0.8723 - val_loss: 0.3689 - val_accuracy: 0.8674\n",
      "Epoch 17/20\n",
      "1124/1124 [==============================] - 1s 816us/step - loss: 0.3640 - accuracy: 0.8723 - val_loss: 0.3636 - val_accuracy: 0.8677\n",
      "Epoch 18/20\n",
      "1124/1124 [==============================] - 1s 803us/step - loss: 0.3589 - accuracy: 0.8746 - val_loss: 0.3622 - val_accuracy: 0.8679\n",
      "Epoch 19/20\n",
      "1124/1124 [==============================] - 1s 801us/step - loss: 0.3552 - accuracy: 0.8755 - val_loss: 0.3633 - val_accuracy: 0.8679\n",
      "Epoch 20/20\n",
      "1124/1124 [==============================] - 1s 806us/step - loss: 0.3506 - accuracy: 0.8783 - val_loss: 0.3533 - val_accuracy: 0.8723\n"
     ]
    }
   ],
   "source": [
    "train = modelA.fit(xTrainA, yTrainA, epochs=20, validation_data=(xValidA, yValidA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 393us/step - loss: 0.3806 - accuracy: 0.8643\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.38064277172088623, 0.8642500042915344]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelA.evaluate(xTestA, yTestA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelA.save('modelA.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ModelB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelB = keras.models.Sequential()\n",
    "modelB.add(keras.layers.Flatten(input_shape=[28,28]))\n",
    "for hidden_i in (200, 150,100, 50):\n",
    "    modelB.add(keras.layers.Dense(hidden_i, activation='relu'))\n",
    "modelB.add(keras.layers.Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_1 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 200)               157000    \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 150)               30150     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 100)               15100     \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 207,351\n",
      "Trainable params: 207,351\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelB.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.SGD`.\n"
     ]
    }
   ],
   "source": [
    "modelB.compile(loss='binary_crossentropy', optimizer=keras.optimizers.SGD(learning_rate=1e-3), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.7217 - accuracy: 0.4200 - val_loss: 0.7205 - val_accuracy: 0.4319\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7155 - accuracy: 0.4100 - val_loss: 0.7141 - val_accuracy: 0.4255\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7089 - accuracy: 0.4200 - val_loss: 0.7061 - val_accuracy: 0.4286\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7004 - accuracy: 0.4700 - val_loss: 0.6972 - val_accuracy: 0.4545\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.6917 - accuracy: 0.5400 - val_loss: 0.6917 - val_accuracy: 0.4946\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.6857 - accuracy: 0.5900 - val_loss: 0.6863 - val_accuracy: 0.5630\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.6801 - accuracy: 0.6300 - val_loss: 0.6802 - val_accuracy: 0.6348\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.6740 - accuracy: 0.6300 - val_loss: 0.6741 - val_accuracy: 0.6742\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.6678 - accuracy: 0.7000 - val_loss: 0.6687 - val_accuracy: 0.6978\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.6623 - accuracy: 0.7100 - val_loss: 0.6634 - val_accuracy: 0.7052\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.6570 - accuracy: 0.6900 - val_loss: 0.6572 - val_accuracy: 0.6944\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.6509 - accuracy: 0.6600 - val_loss: 0.6533 - val_accuracy: 0.6883\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.6469 - accuracy: 0.6700 - val_loss: 0.6494 - val_accuracy: 0.6836\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.6428 - accuracy: 0.6600 - val_loss: 0.6442 - val_accuracy: 0.6691\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.6375 - accuracy: 0.6100 - val_loss: 0.6401 - val_accuracy: 0.6627\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.6333 - accuracy: 0.6000 - val_loss: 0.6367 - val_accuracy: 0.6580\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.6297 - accuracy: 0.6000 - val_loss: 0.6343 - val_accuracy: 0.6624\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.6272 - accuracy: 0.6000 - val_loss: 0.6312 - val_accuracy: 0.6584\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.6238 - accuracy: 0.6000 - val_loss: 0.6260 - val_accuracy: 0.6348\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.6186 - accuracy: 0.5900 - val_loss: 0.6224 - val_accuracy: 0.6270\n"
     ]
    }
   ],
   "source": [
    "train = modelB.fit(xTrainB, yTrainB, epochs=20, validation_data=(xValidB, yValidB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 420us/step - loss: 0.6201 - accuracy: 0.6300\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6200679540634155, 0.6299999952316284]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelB.evaluate(xTestB, yTestB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model_tr(Trainsfer Learning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Load modelA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelA = keras.models.load_model('modelA.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 200)               157000    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 150)               30150     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 100)               15100     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 8)                 408       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 207,708\n",
      "Trainable params: 207,708\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelA.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Reuse Lower Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelTr = keras.models.Sequential(modelA.layers[:-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 200)               157000    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 150)               30150     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 100)               15100     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 202,250\n",
      "Trainable params: 202,250\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelTr.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Replace Upper Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelTr.add(keras.layers.Dense(80,activation='relu'))\n",
    "modelTr.add(keras.layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 200)               157000    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 150)               30150     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 100)               15100     \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 80)                8080      \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 81        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 210,411\n",
      "Trainable params: 210,411\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelTr.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Train in the first few epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in modelTr.layers[:-2]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "____________________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   Trainable  \n",
      "============================================================================\n",
      " flatten (Flatten)           (None, 784)               0         N          \n",
      "                                                                            \n",
      " dense (Dense)               (None, 200)               157000    N          \n",
      "                                                                            \n",
      " dense_1 (Dense)             (None, 150)               30150     N          \n",
      "                                                                            \n",
      " dense_2 (Dense)             (None, 100)               15100     N          \n",
      "                                                                            \n",
      " dense_10 (Dense)            (None, 80)                8080      Y          \n",
      "                                                                            \n",
      " dense_11 (Dense)            (None, 1)                 81        Y          \n",
      "                                                                            \n",
      "============================================================================\n",
      "Total params: 210,411\n",
      "Trainable params: 8,161\n",
      "Non-trainable params: 202,250\n",
      "____________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelTr.summary(show_trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.SGD`.\n"
     ]
    }
   ],
   "source": [
    "modelTr.compile(loss='binary_crossentropy', optimizer=keras.optimizers.SGD(learning_rate=1e-3),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 39ms/step - loss: 0.9814 - accuracy: 0.5100 - val_loss: 0.7990 - val_accuracy: 0.5142\n",
      "Epoch 2/4\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.7444 - accuracy: 0.5300 - val_loss: 0.6221 - val_accuracy: 0.6432\n",
      "Epoch 3/4\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.5908 - accuracy: 0.7300 - val_loss: 0.5066 - val_accuracy: 0.9710\n",
      "Epoch 4/4\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4913 - accuracy: 1.0000 - val_loss: 0.4447 - val_accuracy: 0.9801\n"
     ]
    }
   ],
   "source": [
    "train = modelTr.fit(xTrainB, yTrainB, epochs=4, validation_data=(xValidB, yValidB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Continue training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in modelTr.layers[:-2]:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "____________________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   Trainable  \n",
      "============================================================================\n",
      " flatten (Flatten)           (None, 784)               0         Y          \n",
      "                                                                            \n",
      " dense (Dense)               (None, 200)               157000    Y          \n",
      "                                                                            \n",
      " dense_1 (Dense)             (None, 150)               30150     Y          \n",
      "                                                                            \n",
      " dense_2 (Dense)             (None, 100)               15100     Y          \n",
      "                                                                            \n",
      " dense_10 (Dense)            (None, 80)                8080      Y          \n",
      "                                                                            \n",
      " dense_11 (Dense)            (None, 1)                 81        Y          \n",
      "                                                                            \n",
      "============================================================================\n",
      "Total params: 210,411\n",
      "Trainable params: 210,411\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelTr.summary(show_trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.SGD`.\n"
     ]
    }
   ],
   "source": [
    "modelTr.compile(loss='binary_crossentropy', optimizer=keras.optimizers.SGD(learning_rate=1e-3),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.4319 - accuracy: 0.9800 - val_loss: 0.4104 - val_accuracy: 0.9791\n",
      "Epoch 2/16\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3999 - accuracy: 0.9800 - val_loss: 0.3835 - val_accuracy: 0.9791\n",
      "Epoch 3/16\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3740 - accuracy: 0.9800 - val_loss: 0.3609 - val_accuracy: 0.9781\n",
      "Epoch 4/16\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.3518 - accuracy: 0.9800 - val_loss: 0.3434 - val_accuracy: 0.9744\n",
      "Epoch 5/16\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3352 - accuracy: 0.9800 - val_loss: 0.3288 - val_accuracy: 0.9801\n",
      "Epoch 6/16\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3195 - accuracy: 0.9800 - val_loss: 0.3155 - val_accuracy: 0.9835\n",
      "Epoch 7/16\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3062 - accuracy: 0.9800 - val_loss: 0.3030 - val_accuracy: 0.9848\n",
      "Epoch 8/16\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.2940 - accuracy: 0.9900 - val_loss: 0.2925 - val_accuracy: 0.9869\n",
      "Epoch 9/16\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.2829 - accuracy: 1.0000 - val_loss: 0.2818 - val_accuracy: 0.9875\n",
      "Epoch 10/16\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2721 - accuracy: 1.0000 - val_loss: 0.2722 - val_accuracy: 0.9885\n",
      "Epoch 11/16\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2624 - accuracy: 1.0000 - val_loss: 0.2637 - val_accuracy: 0.9885\n",
      "Epoch 12/16\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.2537 - accuracy: 1.0000 - val_loss: 0.2546 - val_accuracy: 0.9909\n",
      "Epoch 13/16\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.2448 - accuracy: 1.0000 - val_loss: 0.2460 - val_accuracy: 0.9933\n",
      "Epoch 14/16\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.2364 - accuracy: 1.0000 - val_loss: 0.2391 - val_accuracy: 0.9919\n",
      "Epoch 15/16\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.2291 - accuracy: 1.0000 - val_loss: 0.2321 - val_accuracy: 0.9933\n",
      "Epoch 16/16\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.2222 - accuracy: 1.0000 - val_loss: 0.2247 - val_accuracy: 0.9933\n"
     ]
    }
   ],
   "source": [
    "train = modelTr.fit(xTrainB, yTrainB, epochs=16, validation_data=(xValidB, yValidB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare modelTr vs modelB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 539us/step - loss: 0.2217 - accuracy: 0.9945\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.22172072529792786, 0.9944999814033508]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelTr.evaluate(xTestB, yTestB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 555us/step - loss: 0.6201 - accuracy: 0.6300\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6200679540634155, 0.6299999952316284]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelB.evaluate(xTestB, yTestB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_p311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
